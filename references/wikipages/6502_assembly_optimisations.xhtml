<?xml version="1.0" ?><!DOCTYPE html  PUBLIC '-//W3C//DTD XHTML 1.0 Transitional//EN'  'http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd'><html xmlns="http://www.w3.org/1999/xhtml"><head><title>6502 assembly optimisations</title>
<meta content="width=display-width" name="viewport"/>
<link href="w.css" rel="stylesheet" type="text/css"/>
<script src="w.js" type="text/javascript"/>
</head><body><h1>6502 assembly optimisations</h1><div class="article">
<p>This page is about optimisations that are possible in assembly language, or various things one programmer has to keep in mind to make his code as optimal as possible.
</p><p>There is two major kind of optimisations: Optimisation for speed (code executes in fewer cycles) and optimisation for size (the code takes fewer bytes).
</p><p>There is also some other kinds of optimisations, such as constant-executing-time optimisation (code execute in a constant number of cycle no matter what it has to do), or RAM usage optimisation (use as few variables as possible).
Because those optimisations have more to do with the algorithm than with its implementation in assembly, only speed and size optimisations will be discussed in this article.
</p>
<div class="toc" id="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Optimise_both_speed_and_size_of_the_code"><span class="tocnumber">1</span> <span class="toctext">Optimise both speed and size of the code</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Avoid_a_jsr_.2B_rts_chain"><span class="tocnumber">1.1</span> <span class="toctext">Avoid a jsr + rts chain</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Split_word_tables_in_high_and_low_components"><span class="tocnumber">1.2</span> <span class="toctext">Split word tables in high and low components</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Use_Jump_tables_with_RTS_instruction_instead_of_JMP_indirect_instruction"><span class="tocnumber">1.3</span> <span class="toctext">Use Jump tables with RTS instruction instead of JMP indirect instruction</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Use_a_macro_instead_of_a_subroutine_which_is_only_called_once"><span class="tocnumber">1.4</span> <span class="toctext">Use a macro instead of a subroutine which is only called once</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Arithmetic_shift_right"><span class="tocnumber">1.5</span> <span class="toctext">Arithmetic shift right</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Easily_test_2_upper_bits_of_a_variable"><span class="tocnumber">1.6</span> <span class="toctext">Easily test 2 upper bits of a variable</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Negating_a_value_without_temporaries"><span class="tocnumber">1.7</span> <span class="toctext">Negating a value without temporaries</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="#Avoiding_the_need_for_CLC.2FSEC_with_ADC.2FSBC"><span class="tocnumber">1.8</span> <span class="toctext">Avoiding the need for CLC/SEC with ADC/SBC</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Test_bits_in_decreasing_order"><span class="tocnumber">1.9</span> <span class="toctext">Test bits in decreasing order</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#Test_bits_in_increasing_order"><span class="tocnumber">1.10</span> <span class="toctext">Test bits in increasing order</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#Test_bits_without_destroying_the_accumulator"><span class="tocnumber">1.11</span> <span class="toctext">Test bits without destroying the accumulator</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#Use_opposite_rotate_instead_of_a_great_number_of_shifts"><span class="tocnumber">1.12</span> <span class="toctext">Use opposite rotate instead of a great number of shifts</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-14"><a href="#Optimise_speed_at_the_expense_of_size"><span class="tocnumber">2</span> <span class="toctext">Optimise speed at the expense of size</span></a>
<ul>
<li class="toclevel-2 tocsection-15"><a href="#Use_identity_look-up_table_instead_of_temp_variable"><span class="tocnumber">2.1</span> <span class="toctext">Use identity look-up table instead of temp variable</span></a></li>
<li class="toclevel-2 tocsection-16"><a href="#Use_look-up_table_to_shift_left_4_times"><span class="tocnumber">2.2</span> <span class="toctext">Use look-up table to shift left 4 times</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-17"><a href="#Optimise_code_size_at_the_expense_of_cycles"><span class="tocnumber">3</span> <span class="toctext">Optimise code size at the expense of cycles</span></a>
<ul>
<li class="toclevel-2 tocsection-18"><a href="#Use_the_stack_instead_of_a_temp_variable"><span class="tocnumber">3.1</span> <span class="toctext">Use the stack instead of a temp variable</span></a></li>
<li class="toclevel-2 tocsection-19"><a href="#Use_an_.22intelligent.22_argument_system"><span class="tocnumber">3.2</span> <span class="toctext">Use an &quot;intelligent&quot; argument system</span></a></li>
<li class="toclevel-2 tocsection-20"><a href="#Using_relative_branch_instruction_instead_of_absolute"><span class="tocnumber">3.3</span> <span class="toctext">Using relative branch instruction instead of absolute</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-21"><a href="#See_also"><span class="tocnumber">4</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-22"><a href="#Notes"><span class="tocnumber">5</span> <span class="toctext">Notes</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Optimise_both_speed_and_size_of_the_code">Optimise both speed and size of the code</span></h2>
<h3><span class="mw-headline" id="Avoid_a_jsr_.2B_rts_chain">Avoid a jsr + rts chain</span></h3>
<p><span id="Tail_call"/>A <a class="extiw" href="http://en.wikipedia.org/wiki/tail_call" title="wikipedia:tail call">tail call</a> occurs when a subroutine finishes by calling another subroutine. This can be optimised into a JMP instruction:
</p>
<pre>
MySubroutine
  lda Foo
  sta Bar
  jsr SomeRandomRoutine
  rts
</pre>
<p>becomes :
</p>
<pre>
MySubroutine
  lda Foo
  sta Bar
  jmp SomeRandomRoutine
</pre>
<p>Savings : 9 cycles, 1 byte
</p>
<h3><span class="mw-headline" id="Split_word_tables_in_high_and_low_components">Split word tables in high and low components</span></h3>
<p>This optimisation is not human friendly, makes the source code much bigger, but still makes the compiled<sup class="reference" id="cite_ref-compile_pedantry_1-0"><a href="#cite_note-compile_pedantry-1">[1]</a></sup> size smaller and faster:
</p>
<pre>
Example
  lda FooBar
  asl A
  tax
  lda PointerTable,X
  sta Temp
  lda PointerTable+1,X
  sta Temp+1
  ....

PointerTable
  .dw Pointer1, Pointer2, ....
</pre>
<p>Becomes :
</p>
<pre>
Example
  ldx FooBar
  lda PointerTableL,X
  sta Temp
  lda PointerTableH,X
  sta Temp+1
  ....

PointerTableL
  .byt &lt;Pointer1, &lt;Pointer2, ....

PointerTableH
  .byt &gt;Pointer1, &gt;Pointer2, ....
</pre>
<p>Some assemblers may have a way to implement a macro to automatically make the table coded like this (Unofficial MagicKit Assembler is one such program).
</p><p>Savings : 2 bytes, 4 cycles
</p>
<h3><span class="mw-headline" id="Use_Jump_tables_with_RTS_instruction_instead_of_JMP_indirect_instruction">Use Jump tables with RTS instruction instead of JMP indirect instruction</span></h3>
<p><span id="RTS_Trick"/>The so-called <a href="RTS_Trick.xhtml" title="RTS Trick">RTS Trick</a> is a method of implementing jump tables by pushing a subroutine's entry point to the stack.
</p>
<pre>
; This:

  ldx JumpEntry
  lda PointerTableL,X
  sta Temp
  lda PointerTableH,X
  sta Temp+1
  jmp [Temp]

; becomes this:

  ldx JumpEntry
  lda PointerTableH,X
  pha
  lda PointerTableL,X
  pha
  rts
</pre>
<p>Note that PointerTable entries must point to one byte <i>before</i> the intended target when the RTS trick is used, because RTS will add 1 to the offset.
</p><p>Savings : 4 bytes, 1 cycle.
</p><p>To squeeze slightly more, it's possible to combine this with the tail call optimization:
</p>
<pre>
; This:

  jsr SomeOtherFunction  ; MUST NOT modify JumpEntry
  ldx JumpEntry
  lda PointerTableH,X
  pha
  lda PointerTableL,X
  pha
  rts

; Becomes this:

  ldx JumpEntry
  lda PointerTableH,X
  pha
  lda PointerTableL,X
  pha
  jmp SomeOtherFunction
</pre>
<p>Here, the CPU runs SomeOtherFunction, then returns to the function from the jump table, then returns to what called this dispatcher.
</p>
<h3><span class="mw-headline" id="Use_a_macro_instead_of_a_subroutine_which_is_only_called_once">Use a macro instead of a subroutine which is only called once</span></h3>
<p>What is the point to call a subroutine if you only call it at a single place?
It would be more optimal to just insert the code where the subroutine is called.
However this makes the code less structured and harder to understand.
<a class="extiw" href="http://en.wikipedia.org/wiki/Inline_expansion" title="wikipedia:Inline expansion">Inline expansion</a> of a subroutine into another subroutine can be done with a macro.
One drawback is that if the subroutine is called in a loop, it may require some JMPing to work around the 128-byte limit on branch length.
</p><p>How macros are used depends on the assembler so no code examples will be placed here to avoid further confusion.
In C, the <code>static inline</code> keyword acts as a hint to expand a function as a macro.
</p><p>Savings : 4 bytes, 12 cycles.
</p>
<h3><span class="mw-headline" id="Arithmetic_shift_right">Arithmetic shift right</span></h3>
<p>Compact way to divide a variable by 2 but keep its sign:
</p>
<pre>
   cmp #$80
   ror A
</pre>
<h3><span class="mw-headline" id="Easily_test_2_upper_bits_of_a_variable">Easily test 2 upper bits of a variable</span></h3>
<pre>
    lda FooBar
    asl A         ;C = b7, N = b6
</pre>
<p>Alternative:
</p>
<pre>
    bit Foobar    ;N = b7, V = b6, regardless of the value of A.
</pre>
<p>This can be e.g. used to poll the sprite-0-hit flag in $2002.
</p>
<h3><span class="mw-headline" id="Negating_a_value_without_temporaries">Negating a value without temporaries</span></h3>
<pre>
   eor #$FF
   clc
   adc #1
</pre>
<h3><span class="mw-headline" id="Avoiding_the_need_for_CLC.2FSEC_with_ADC.2FSBC">Avoiding the need for CLC/SEC with ADC/SBC</span></h3>
<p>If you are using ADC #imm, and you know your carry is already cleared,
you do not need to do CLC. However, if you <i>know</i> that carry is <i>set</i>
(for example, your code is located in a branch that is only ever entered with a BCS instruction),
you can still avoid using CLC by just doing ADC #(value-1).
The <code>PLOT</code> subroutine in the Apple II Monitor uses this.
</p><p>Similarly for SBC #imm: If you know <i>know</i> that carry is <i>clear</i>,
you can still avoid using SEC by just doing SBC #(value+1).
</p>
<h3><span class="mw-headline" id="Test_bits_in_decreasing_order">Test bits in decreasing order</span></h3>
<pre>
   lda foobar 
   bmi bit7_set 
   cmp #$40  ; we know that bit 7 wasn't set 
   bcs bit6_set 
   cmp #$20 
   bcs bit5_set 
             ; and so on
</pre>
<p>Or if you do not need to preserve the value of A:
</p>
<pre>
   lda foobar 
   asl
   bcs bit7_set 
   asl
   bcs bit6_set 
   asl
   bcs bit5_set 
             ; and so on
</pre>
<p>This saves one byte per comparison, but 2 cycles more are used because of the extra ASL.
</p>
<h3><span class="mw-headline" id="Test_bits_in_increasing_order">Test bits in increasing order</span></h3>
<pre>
   lda foobar 
   lsr
   bcs bit0_set
   lsr
   bcs bit1_set
   lsr
   bcs bit2_set
             ; and so on
</pre>
<p>Note: This does not preserve the value of A.
</p>
<h3><span class="mw-headline" id="Test_bits_without_destroying_the_accumulator">Test bits without destroying the accumulator</span></h3>
<p>The AND instruction can be used to test bits, but this destroy the value in the accumulator.
The BIT can do this but it has no immediate adressing mode.
A way to do it is to look for an opcode that has the bits you want to test, and use bit $xxxx on this opcode.
</p>
<pre>
Example
   lda foobar
   and #$30
   beq bits_clear
   lda foobar
   ....

bits_clear
   lda foobar
   .....
</pre>
<p>becomes :
</p>
<pre>
Example
   lda foobar
   bit _bmi_instruction ;equivalent to and #$30 but preserves A
   beq bits_clear
   ....

bits_clear
   .....

anywhere_in_the_code
    ....
_bmi_instruction    ;The BMI opcode = $30
    bmi somewhere
</pre>
<p>Savings : 2 cycles, 3 bytes
</p>
<h3><span class="mw-headline" id="Use_opposite_rotate_instead_of_a_great_number_of_shifts">Use opposite rotate instead of a great number of shifts</span></h3>
<p>To retrieve the 3 highest bits of a value in the low positions, you might be tempted to do 5 LSRs in a row. However, if you do not need the 5 top bits to be cleared, this is more efficient:
</p>
<pre>
  lda value   ; got: 76543210 c
  rol         ; got: 6543210c 7
  rol         ; got: 543210c7 6 
  rol         ; got: 43210c76 5
  rol         ; got: 3210c765 4
  ; Only care about these ^^^
</pre>
<p>It works the same for replacing 5 ASLs with 4 RORs.
</p><p>To replace 6 ASLs you can use 3 RORs:
</p>
<pre>
  lda value   ; got: 76453210 c
  ror         ; got: c7654321 0
  ror         ; got: 0c765432 1
  ror         ; got: 10c76543 2
  and #$C0    ; got: 10------
</pre>
<h2><span class="mw-headline" id="Optimise_speed_at_the_expense_of_size">Optimise speed at the expense of size</span></h2>
<p>Those optimisations will make code faster to execute, but use more ROM. Therefore, it is useful in NMI routines and other things that need to run fast.
</p>
<h3><span class="mw-headline" id="Use_identity_look-up_table_instead_of_temp_variable">Use identity look-up table instead of temp variable</span></h3>
<pre>
Example
    ldx Foo
    lda Bar
    stx Temp
    clc
    adc Temp    ;A = Foo + Bar
</pre>
<p>becomes :
</p>
<pre>
Example
    ldx Foo
    lda Bar
    clc
    adc Identity,X    ;A = Foo + Bar

Identity
    .byt $00, $01, $02, $03, .....
</pre>
<p>If your program is very large, it is possible that this way uses slightly less ROM; also, it might save one byte of RAM in some circumstances.
</p><p>Savings : 2 cycles
</p>
<h3><span class="mw-headline" id="Use_look-up_table_to_shift_left_4_times">Use look-up table to shift left 4 times</span></h3>
<p>Provided that the high nibble is already cleared, you can shift left by 4 by making a multiplication look-up table.
</p>
<pre>
Example:
  lda rownum
  asl A
  asl A
  asl A
  asl A
  rts
</pre>
<p>becomes
</p>
<pre>
Example:
  ldx rownum
  lda times_sixteen,x
  rts

times_sixteen:
  .byt $00, $10, $20, $30, $40, $50, $60, $70
  .byt $80, $90, $A0, $B0, $C0, $D0, $E0, $F0
</pre>
<p>In very large programs, this might save some ROM space. However, it will use up the X register, so it might not be ideal.
</p><p>Savings: 4 cycles
</p>
<h2><span class="mw-headline" id="Optimise_code_size_at_the_expense_of_cycles">Optimise code size at the expense of cycles</span></h2>
<p>Those optimisations will produce code that is smaller but takes more cycles to execute. Therefore, it can be used in the parts of the program that do not have to be fast.
</p>
<h3><span class="mw-headline" id="Use_the_stack_instead_of_a_temp_variable">Use the stack instead of a temp variable</span></h3>
<pre>
Example
   lda Foo
   sta Temp
   lda Bar
   ....
   ....
   lda Temp   ;Restores Foo
   .....
</pre>
<p>becomes:
</p>
<pre>
Example
   lda Foo
   pha
   lda Bar
   ....
   ....
   pla   ;Restores Foo
   .....
</pre>
<p>Savings : 2 bytes.
</p>
<h3><span class="mw-headline" id="Use_an_.22intelligent.22_argument_system">Use an &quot;intelligent&quot; argument system</span></h3>
<p>Each time a routine needs multiple bytes of arguments (&gt;3) it's hard to code it without wasting a lot of bytes.
</p>
<pre>
Example
   lda Argument1
   sta Temp
   lda Argument2
   ldx Argument3
   ldy Argument4
   jsr RoutineWhichNeeds4Args
   .....
</pre>
<p>Becomes something like:
</p>
<pre>
Example
   jsr PassArguments
   .dw RoutineWhichNeeds4Args
   .db Argument1, Argument2, Argument3, Argument4
   .db $00
   ....

PassArguments
   pla 
   tay 
   pla 
   pha                    ; put the high byte back 
   sta pointer+1 
   ldx #$00 
   beq SKIP 
LOOP 
   sta parameters,x 
   inx 
SKIP 
   iny                    ; pointing one short first pass here fixes that 
   lda (pointer),y 
   bne LOOP      
   iny 
   lda (pointer),y 
   beq LOOP

   dey                    ; fix the return address guess we can't return to a 
                         ;  break        
   tya 
   pha 
   jmp (parameters)
</pre>
<p>Syscalls in Apple ProDOS<sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup> and FDS BIOS work this way.
</p><p>Savings : Complicated to estimate - only saves bytes if the trick is used fairly often across the program, in order to compensate for the size of the PassArguments routine.
</p>
<h3><span class="mw-headline" id="Using_relative_branch_instruction_instead_of_absolute">Using relative branch instruction instead of absolute</span></h3>
<p>If the state of one of the processor flags is already known at this point and the branch target is not too far away, then you can use a condition branch instruction.
</p><p>Savings : 1 byte.
</p>
<h2><span class="mw-headline" id="See_also">See also</span></h2>
<ul><li><a href="Synthetic_instructions.xhtml" title="Synthetic instructions">Synthetic instructions</a></li></ul>
<h2><span class="mw-headline" id="Notes">Notes</span></h2>
<ol class="references">
<li id="cite_note-compile_pedantry-1"><span class="mw-cite-backlink"><a href="#cite_ref-compile_pedantry_1-0">↑</a></span> <span class="reference-text">Pedants may complain that &quot;compile&quot; is incorrect terminology for &quot;translate a program written in assembly language into object code&quot;. But it is the most familiar term meaning &quot;translate a program, no matter the language, into object code&quot;, and the same issues apply to code generators within a compiler that targets the 6502 as to programs written in 6502 assembly language.</span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><a href="#cite_ref-2">↑</a></span> <span class="reference-text"><i>ProDOS 8 Technical Reference Manual</i></span>
</li>
</ol>

<!-- 
NewPP limit report
CPU time usage: 0.123 seconds
Real time usage: 0.128 seconds
Preprocessor visited node count: 358/1000000
Preprocessor generated node count: 758/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 3/40
Expensive parser function count: 0/100
-->

<!-- Saved in parser cache with key nesdev_wiki-mw1_:pcache:idhash:763-1!*!0!!en!*!* and timestamp 20160208215444 and revision id 9016
 -->
</div></body></html>